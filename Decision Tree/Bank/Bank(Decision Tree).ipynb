{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f85c2d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the  Depth:\n",
      "5\n",
      "Select the attribute: 1 = Entropy, 2 = Gini_Index, 3 = Majority_Error\n",
      "3\n",
      "The selected depth is: 5\n",
      "training error = 0.6452  test error = 0.6758\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "attribute_value = {}\n",
    "\n",
    "def Get_Num_Values(dataframe, value):\n",
    "    return dataframe.loc[dataframe['label'] == value].count()\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, values=None, label=None):\n",
    "        self.attribute = attribute\n",
    "        self.values = values\n",
    "        self.next = {}\n",
    "\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def Entropy(v, s):\n",
    "    E = (v/s)*np.log2(v/s) * -1\n",
    "    return E\n",
    "\n",
    "def Gini_Index(p, s):\n",
    "    GI = np.power(p/s,2)\n",
    "    return GI\n",
    "    \n",
    "def Majority(p, s):\n",
    "    ME = (s-p)/s\n",
    "    return ME\n",
    "    \n",
    "def Information_Gain(total, s_size, value_numbers, c):\n",
    "    a = 0\n",
    "    i = 0\n",
    "    while (i < value_numbers.size):\n",
    "        a += (value_numbers[i]/s_size) * c[i]\n",
    "        i += 1\n",
    "    return total - a \n",
    "\n",
    "def Common_Label(data):\n",
    "    return data['label'].value_counts().max()\n",
    "\n",
    "def Get_Total_Value(label_values,num_rows,d):\n",
    "    if d ==1:\n",
    "        total_value = 0\n",
    "        for v in label_values:\n",
    "            total_value += Entropy(v, num_rows)\n",
    "        return total_value\n",
    "    if d ==2:\n",
    "        total_value = 1\n",
    "        for v in label_values:\n",
    "            total_value -= Gini(v, num_rows)\n",
    "        return total_value\n",
    "    if d == 3:\n",
    "        total_value = 0\n",
    "        for v in label_values:\n",
    "            total_value += (num_rows-v)/num_rows\n",
    "        return total_value\n",
    "\n",
    "\n",
    "def Get_Entropy(data,attributes, total_entropy):\n",
    "    best_attribute = None\n",
    "    best_info_gain = None\n",
    "    for attribute in attributes:\n",
    "        if(attribute != 'label'):\n",
    "            attribute_values = pd.unique(data[attribute])\n",
    "            entropies = []\n",
    "\n",
    "            for value in attribute_values:\n",
    "                val_bool = data[attribute] == value\n",
    "                filtered_data = data[val_bool]\n",
    "                label_counts = filtered_data['label'].value_counts()\n",
    "                value_entropy = 0\n",
    "                for label in label_counts:\n",
    "                    value_entropy += Entropy(label, filtered_data.shape[0])\n",
    "                entropies.append(value_entropy)\n",
    "            attribute_info_gain = Information_Gain(total_entropy, data.shape[0], data[attribute].value_counts(), entropies)\n",
    "            if best_info_gain == None or attribute_info_gain > best_info_gain:\n",
    "                best_attribute = attribute\n",
    "                best_info_gain = attribute_info_gain\n",
    "\n",
    "    root_node = Node(best_attribute, pd.unique(data[best_attribute]))\n",
    "    return root_node, best_info_gain\n",
    "\n",
    "def Get_Gini(data,attributes, total_gini):\n",
    "    best_attribute = None\n",
    "    best_info_gain = None\n",
    "    for attribute in attributes:\n",
    "        if(attribute != 'label'):\n",
    "            attribute_values = pd.unique(data[attribute])\n",
    "            gini_indexes = []\n",
    "\n",
    "            for value in attribute_values:\n",
    "                val_bool = data[attribute] == value\n",
    "                filtered_data = data[val_bool]\n",
    "                label_counts = filtered_data['label'].value_counts()\n",
    "                value_gini = 1\n",
    "                for label in label_counts:\n",
    "                    value_gini -= Gini(label, filtered_data.shape[0])\n",
    "                gini_indexes.append(value_gini)\n",
    "            attribute_info_gain = Information_Gain(total_gini, data.shape[0], data[attribute].value_counts(), gini_indexes)\n",
    "            if best_info_gain == None or attribute_info_gain > best_info_gain:\n",
    "                best_attribute = attribute\n",
    "                best_info_gain = attribute_info_gain\n",
    "\n",
    "    root_node = Node(best_attribute, pd.unique(data[best_attribute]))\n",
    "    return root_node, best_info_gain\n",
    "\n",
    "def Get_Majority(data,attributes, total_majority):\n",
    "    best_attribute = None\n",
    "    best_info_gain = None\n",
    "    for attribute in attributes:\n",
    "        if(attribute != 'label'):\n",
    "            attribute_values = pd.unique(data[attribute])\n",
    "            majority_errors = []\n",
    "\n",
    "            for value in attribute_values:\n",
    "                val_bool = data[attribute] == value\n",
    "                filtered_data = data[val_bool]\n",
    "                label_counts = filtered_data['label'].value_counts()\n",
    "                value_majority = 1\n",
    "                for label in label_counts:\n",
    "                    value_majority += Majority(label, filtered_data.shape[0])\n",
    "                majority_errors.append(value_majority)\n",
    "            attribute_info_gain = Information_Gain(total_majority, data.shape[0], data[attribute].value_counts(), majority_errors)\n",
    "            if best_info_gain == None or attribute_info_gain > best_info_gain:\n",
    "                best_attribute = attribute\n",
    "                best_info_gain = attribute_info_gain\n",
    "\n",
    "    root_node = Node(best_attribute, pd.unique(data[best_attribute]))\n",
    "    return root_node, best_info_gain\n",
    "\n",
    "\n",
    "\n",
    "def ID3(data, attributes, total_entropy, defined_depth, d):\n",
    "    if defined_depth == 0:\n",
    "        return Node(label = Common_Label(data))\n",
    "\n",
    "    if len(pd.unique(data['label'])) == 1:\n",
    "        return Node(label=pd.unique(data['label'])[0])\n",
    "\n",
    "    if len(attributes) == 0:\n",
    "        return Node(label= Common_Label(data))\n",
    "\n",
    "\n",
    "    if d == 1:\n",
    "        root_node, new_error = Get_Entropy(data, attributes, total_entropy)\n",
    "    if d == 2:\n",
    "        root_node, new_error = Get_Gini(data, attributes, total_entropy)\n",
    "    if d == 3:\n",
    "        root_node, new_error = Get_Majority(data, attributes, total_entropy)\n",
    "    for value in attribute_value[root_node.attribute]:\n",
    "\n",
    "        is_val = data[root_node.attribute] == value\n",
    "        value_subset = data[is_val]\n",
    "\n",
    "        length = len(value_subset.index)\n",
    "        if length == 0:\n",
    "            root_node.next[value] = Node(label= Common_Label(data))\n",
    "        else:\n",
    "            new_attributes = attributes[:]\n",
    "            new_attributes.remove(root_node.attribute)\n",
    "            new_depth = defined_depth -1\n",
    "            root_node.next[value] = ID3(value_subset,new_attributes, new_error, new_depth, d)\n",
    "    return root_node\n",
    "\n",
    "def Get_Accuracy(root_node, data):\n",
    "    wrong_predictions = 0\n",
    "    i = 0\n",
    "    while i < data.shape[0]:\n",
    "        current_node = root_node\n",
    "        while current_node.label == None:\n",
    "            current_node = current_node.next[data[current_node.attribute].iloc[i]]\n",
    "        if current_node.label != data['label'].iloc[i]:\n",
    "            wrong_predictions += 1\n",
    "        i += 1\n",
    "    return wrong_predictions/data.shape[0]\n",
    "\n",
    "def Get_Data(data, columns):\n",
    "    for column in columns:\n",
    "        attribute_value[column] = pd.unique(data[column])\n",
    "\n",
    "\n",
    "def Replace_Numeric_Values(data, column_names):\n",
    "    for column in column_names:\n",
    "        if data.dtypes[column] == np.int64:\n",
    "            median_value = np.median(data[column].values)\n",
    "            i = 0\n",
    "            while i < len(data[column].values):\n",
    "                if int(data[column].iloc[i]) < median_value:\n",
    "                    data[column].iloc[i] = '-'\n",
    "                else:\n",
    "                    data[column].iloc[i] = '+'\n",
    "                i += 1\n",
    "\n",
    "def Replace_Unknown_Values(data, column_names):\n",
    "    for column in column_names:\n",
    "        if 'unknown' in pd.unique(data[column]):\n",
    "            value_counts = data[column].value_counts()\n",
    "            value_counts = value_counts.drop(labels=['unknown'])\n",
    "            most_common_value = value_counts.idxmax()\n",
    "            data[column].replace({'unknown': most_common_value}, inplace=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('Enter the  Depth:')\n",
    "    tree_depth = int(input())\n",
    "    print('Select the attribute: 1 = Entropy, 2 = Gini_Index, 3 = Majority_Error')\n",
    "    decider = int(input())\n",
    "\n",
    "\n",
    "    bank_columns = ['age','job','marital','education','default','balance','housing', 'loan', 'contact',\n",
    "    'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'label']\n",
    "    data = pd.read_csv(\"train.csv\", header=None, names=bank_columns, delimiter=',')\n",
    "    test_data = pd.read_csv(\"test.csv\", header=None, names=bank_columns, delimiter=',')\n",
    "\n",
    "\n",
    "    Replace_Numeric_Values(data, bank_columns)\n",
    "    Replace_Numeric_Values(test_data, bank_columns)\n",
    "    Replace_Unknown_Values(data, bank_columns)\n",
    "    Replace_Unknown_Values(test_data, bank_columns)\n",
    "\n",
    "\n",
    "    Get_Data(data, bank_columns)\n",
    "\n",
    "\n",
    "    num_rows = data.shape[0]\n",
    "    total_label_values = data['label'].value_counts()\n",
    "    total_error = Get_Total_Value(total_label_values, num_rows, decider)\n",
    "\n",
    "    bank_columns.remove('label')\n",
    "\n",
    "    root_node = ID3(data, bank_columns, total_error, tree_depth, decider)\n",
    "\n",
    "\n",
    "    train_error = Get_Accuracy(root_node, data)\n",
    "    test_error = Get_Accuracy(root_node, test_data)\n",
    "\n",
    "    \n",
    "    print('The selected depth is: ' + str(tree_depth))\n",
    "    print('training error = ' + str(train_error) + '  test error = ' + str(test_error))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024f65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7a274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16efc0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee8b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bb41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ac9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b61f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b510a792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5ab5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca26d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cc526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098ec55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5e22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c329bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533770bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e2a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
